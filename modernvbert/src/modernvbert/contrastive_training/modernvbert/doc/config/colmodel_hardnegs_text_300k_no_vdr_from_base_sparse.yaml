model_args:
  model_name_or_path: /home/scur1709/modernvbert/models/sparsemodernvbert_initialization
  model_type: SparseModernVBertM2
  loss_type: SparseBiNegativeCELoss
  loading_kwargs:
    attn_implementation: flash_attention_2
    torch_dtype: bfloat16
    trust_remote_code: true
train_dataset_args:
- dataset_name_or_path: manu/colpali-queries
  loading_kwargs:
    num_negs: 1
- dataset_name_or_path: rlhn/rlhn-300k
  loading_kwargs:
    num_negs: 2
    num_samples: 300000
    subsets:
    - train
tr_args:
  bf16: true
  #ddp_find_unused_parameters: true
  output_dir: models/colmodernvbert_hardnegs_text_300k_from_base_sparse2
  num_train_epochs: 3
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 4
  gradient_checkpointing: false
  gradient_checkpointing_kwargs:
    use_reentrant: false
  # eval_strategy: steps
  dataloader_num_workers: 1
  save_strategy: steps
  save_steps: 500
  save_total_limit: 50
  logging_steps: 10
  warmup_ratio: 0.1
  learning_rate: 0.0002
  run_name: colmodernvbert_hardnegs_text_300k_from_base_sparse
  report_to: wandb
  use_symmetric_loss: false # No symmetric loss with hard negatives
lora_config:
  r: 32
  lora_alpha: 32
  lora_dropout: 0.1
  init_lora_weights: gaussian
  bias: none
  task_type: FEATURE_EXTRACTION
  target_modules: (.*(model.text_model).*(Wo|Wqkv|Wi).*$|.*(custom_text_proj).*$)
eval_config:
  wrapper_cls: ColModernVBertWrapper
  tasks:
  - ViDoRe(v1)
  - ViDoRe(v2)
  batch_size: 32
  output_folder: /results
  encode_kwargs: {}
